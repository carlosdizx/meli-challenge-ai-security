# Reto t√©cnico MeLi: Proposta Desafio - Desenvolvedor - IA

---

# Stack - Technology

[![Langgraph](https://img.shields.io/badge/langchain-1C3C3C)](https://www.langchain.com/langgraph)
[![Scikit-Learn](https://img.shields.io/badge/scikit--learn-%23F7931E.svg)](https://scikit-learn.org/)
[![Python](https://img.shields.io/badge/Python-FFD43B)](https://www.python.org/)
[![Streamlit](https://img.shields.io/badge/Streamlit-FF4B4B)](https://docs.streamlit.io/)
[![FastApi](https://img.shields.io/badge/fastapi-109989)](https://fastapi.tiangolo.com/)
[![Jupyter](https://img.shields.io/badge/jupyter-%23FA0F00.svg)](https://jupyter.org/)
[![Docker](https://img.shields.io/badge/docker-%230db7ed.svg)](https://www.docker.com/)
[![Gemini](https://img.shields.io/badge/Google%20Gemini-8E75B2)](https://gemini.google.com/)

---

# Arquitectura del proyecto

## Grafo de arquitectura

```mermaid
graph LR
    ROOT[MeLi AI & Security]

    subgraph STREAMLIT [.streamlit]
        A1[secrets.toml]
    end

    subgraph AGENTS [agents]
        B1[decision.py]
        B2[ingestion.py]
        B3[predict.py]
        B4[report.py]
        B5[transform.py]
    end

    subgraph APP [app]
        C1[api.py]
        C2[client.py]
        C3[graph.py]
    end

    subgraph COMPONENTS [components]
        D1[results.py]
        D2[sidebar.py]
        D3[uploader.py]
    end

    subgraph CONFIG [config]
        E1[api_config.py]
        E2[gemini_config.py]
    end

    subgraph DTO [dto]
        F1[log_entry.py]
    end

    subgraph EDA [eda]
        G1[risk_based_authentication.ipynb]
    end

    subgraph GRAPH [graph]
        H1[pipeline_state.py]
    end

    subgraph PROMPTS [prompts]
        I1[system_instruction_gemini.py]
    end

    subgraph ROUTERS [routers]
        J1[analyze.py]
        J2[health.py]
    end

    subgraph SCRIPTS [scripts]
        K1[export_to_csv.py]
        K2[export_to_json.py]
        K3[load_dataset.py]
        K4[setup_secrets.py]
        K5[train_models.py]
    end

    subgraph SERVICES [services]
        L1[gemini_service.py]
        L2[model_service.py]
    end

    ROOT --> STREAMLIT
    ROOT --> AGENTS
    ROOT --> APP
    ROOT --> COMPONENTS
    ROOT --> CONFIG
    ROOT --> DTO
    ROOT --> EDA
    ROOT --> GRAPH
    ROOT --> PROMPTS
    ROOT --> ROUTERS
    ROOT --> SCRIPTS
    ROOT --> SERVICES
    ROOT --> N[.gitignore]
    ROOT --> O[docker-compose.yml]
    ROOT --> P[Dockerfile]
    ROOT --> Q[langgraph.json]
    ROOT --> R[README.md]
    ROOT --> S[requirements.txt]
    ROOT --> T[supervisord.conf]
```

## Descripci√≥n de carpetas y archivos

- **.streamlit/** ‚Üí Configuraci√≥n de Streamlit, incluye `secrets.toml`.
- **agents/** ‚Üí Agentes inteligentes:
    - [decision.py](agents%2Fdecision.py) Agentes de decisi√≥n, tiene conexi√≥n a un LLM.
    - [ingestion.py](agents%2Fingestion.py) Agentes carga y validaci√≥n de los datos entrantes.
    - [predict.py](agents%2Fpredict.py) Agentes de predicci√≥n, predice los datos entrantes con base en el modelo
      entrenado.
    - [report.py](agents%2Freport.py) Agentes de reporte, genera un reporte con base en los datos entrantes.
    - [transform.py](agents%2Ftransform.py) Agentes de transformaci√≥n, convierte los datos entrantes para poder ser
      usados en el modelo.
- **app/** ‚Üí C√≥digo principal de la aplicaci√≥n y endpoints FastAPI.
    - [api.py](app%2Fapi.py) App FastApi
    - [client.py](app%2Fclient.py) App Streamlit
    - [graph.py](app%2Fgraph.py) App LangGraph
- **components/** ‚Üí Componentes reutilizables para la interfaz.
    - [results.py](components%2Fresults.py) Componente de resultados, muestra decisiones sugeridas, gr√°fica y listas.
    - [sidebar.py](components%2Fsidebar.py) Componente de sidebar, panel de control y about me.
    - [uploader.py](components%2Fuploader.py) Componente de subida de datos, archivos json o texto del clipboard.
- **config/** ‚Üí Configuraciones generales y par√°metros de modelos.
    - [api_config.py](config%2Fapi_config.py) Configuraci√≥n de FastAPI para usar en el app de streamlit.
    - [gemini_config.py](config%2Fgemini_config.py) Configuraci√≥n de Gemini para usar en los flujos.
- **dto/** ‚Üí Definici√≥n de estructuras de datos (Data Transfer Objects).
    - [log_entry.py](dto%2Flog_entry.py) Mapea y valida los registros entrantes.
- **eda/** ‚Üí Scripts de an√°lisis exploratorio y limpieza de datos.
    - [risk_based_authentication.ipynb](eda%2Frisk_based_authentication.ipynb) An√°lisis exploratorio de datos.
- **graph/** ‚Üí Definici√≥n de recursos para LangGraph.
  - [pipeline_state.py](graph%2Fpipeline_state.py) Configuraci√≥n y estado del grafo de LangGraph.
- **prompts/** ‚Üí Prompts para IA utilizados por los agentes.
  - [system_instruction_gemini.py](prompts%2Fsystem_instruction_gemini.py) Prompt para Gemini.
- **routers/** ‚Üí Endpoints API expuestos mediante FastAPI.
  - [analyze.py](routers%2Fanalyze.py) Ruta para an√°lisis de datos (entrada de datos).
  - [health.py](routers%2Fhealth.py) Ruta para validar healthcheck del API.
- **scripts/** ‚Üí Scripts auxiliares (descarga de dataset, train, etc.).
  - [export_to_csv.py](scripts%2Fexport_to_csv.py) Script para exportar datos a CSV (datos de entrenamiento).
  - [export_to_json.py](scripts%2Fexport_to_json.py) Script para exportar datos a JSON (datos de prueba).
  - [load_dataset.py](scripts%2Fload_dataset.py) Script para descargar datos y preprocesarlos.
  - [setup_secrets.py](scripts%2Fsetup_secrets.py) Script para configurar variables de entorno.
  - [train_models.py](scripts%2Ftrain_models.py) Script para entrenar modelos de ML.
- **services/** ‚Üí L√≥gica de negocio, modelos y predicci√≥n de anomal√≠as con Gemini.
  - [gemini_service.py](services%2Fgemini_service.py) Servicio para sugerencias con Gemini.
  - [model_service.py](services%2Fmodel_service.py) Servicio para predicci√≥n de anomal√≠as con ML.
- [.gitignore](.gitignore) Ignora archivos que no deben ser versionados.
- [docker-compose.yml](docker-compose.yml) Contenerizaci√≥n de la aplicaci√≥n 1-2.
- [Dockerfile](Dockerfile) Contenerizaci√≥n de la aplicaci√≥n 1-1.
- [langgraph.json](langgraph.json) Configuraci√≥n de LangGraph para el flujo de agentes.
- [README.md](README.md) Documentaci√≥n del proyecto.
- [requirements.txt](requirements.txt) Requisitos del proyecto.
- [supervisord.conf](supervisord.conf) Supervisi√≥n de los servicios.


---

# Flujos de agentes

```mermaid
graph TD
    A[__start__] --> B[Ingesti√≥n] --> |DTO: Validaci√≥n, cargue Dataframe| C[Transformaci√≥n]
    C --> |Conversi√≥n factorial y mapeo de datos| D[Predicci√≥n]
    D --> |Modelo ML| E[Decision]
    E --> |Sugerencia de acci√≥n con ML y AI| F[Reporte]
    F --> |An√°lisis de anomal√≠as| G[__end__]
    G --> A
```
----

# Instalaci√≥n del proyecto

Esta gu√≠a te ayudar√° a configurar y ejecutar el proyecto de manera r√°pida y eficiente. Sigue estos pasos para poner
en marcha un entorno de desarrollo robusto, listo para la acci√≥n.

## üõ†Ô∏è Requisitos

- Windows, macOS o Linux
- Python 3.11 (recomendado) o compatible
- Verifica tu versi√≥n:
    - Windows: `py --version` o `python --version`
    - macOS/Linux: `python3 --version` o `python --version`
- Docker (opcional) si prefieres ejecutar todo el sistema de forma integrada y aislada.

‚ö†Ô∏è Nota: Recuerda ejecutar los comandos en la terminal y en la raiz del proyecto.
No uses la terminal (terminal markdown) de este cuaderno‚ö†Ô∏è

## 1) üì¶ Crear el entorno virtual

Un entorno virtual a√≠sla las dependencias de tu proyecto, evitando conflictos con otras instalaciones
de Python. Es una pr√°ctica esencial para un desarrollo limpio.

En la ra√≠z del proyecto, ejecuta:

```bash
python -m venv .venv
```

## 2) ‚ñ∂Ô∏è Activar el entorno virtual

Activar el entorno te permitir√° usar las librer√≠as espec√≠ficas del proyecto.
El comando var√≠a seg√∫n tu sistema operativo y el shell que uses:

- Windows (PowerShell):
  ```powershell
  .\.venv\Scripts\Activate.ps1
  ```
- Windows (CMD):
  ```cmd
  .venv\Scripts\activate.bat
  ```
- macOS/Linux (Bash/Zsh):
  ```bash
  source .venv/bin/activate
  ```
- macOS/Linux (Fish):
  ```fish
  source .venv/bin/activate.fish
  ```

## 3) üêç Verificar la versi√≥n de Python del entorno

Una vez activado el entorno, confirma que est√°s utilizando el int√©rprete correcto:

Windows

```bash
.\.venv\Scripts\python.exe --version
```

macOS/Linux

```bash
.venv/bin/python --version
```

## 4) ‚öôÔ∏è Actualizar pip

```bash
python -m pip install --upgrade pip
```

## 5) ‚ú® Instalar dependencias

Con tu entorno activo y pip actualizado, instala todas las librer√≠as necesarias para que el proyecto funcione
correctamente.
Estas se encuentran listadas en el archivo requirements.txt.

```bash
pip install -r requirements.txt
```

## 6) üîë Configurar variables de entorno

Para que la aplicaci√≥n se conecte con las herramientas y servicios necesarios,
necesitas configurar tus claves y variables. Crea el archivo `.streamlit/secrets.toml`
con la siguiente informaci√≥n, sustituyendo `<tu_api_key>` con tu clave de API de Gemini.

Ejecuta el siguiente script para crear el archivo:

```bash
python -m scripts.setup_secrets
```

Reemplaza `<tu_api_key>` con tu clave de API de Gemini.

## 7) ü¶æ Ejecutar scripts para descargar y preprocesar los datos

Ejecuta estos scripts para preparar el proyecto. El proceso descarga y limpia el conjunto de datos,
y luego entrena los modelos de IA, dej√°ndolos listos para ser utilizados por la API.

```bash
python -m scripts.load_dataset
python -m scripts.train_models
```

Nota: Esto genera varios archivos en la carpeta  `data` que pueden ser usados para
probar la aplicaci√≥n.

---

# Ejecutar aplicaciones

Aqu√≠ ya puedes probar tus aplicaciones. Tienes varias opciones para ejecutar los distintos componentes
del proyecto, seg√∫n tu preferencia:

- Ejecutar de forma individual el API, el cliente y los agentes. Puedes levantar cada aplicaci√≥n de forma separada,
  para pruebas m√°s controladas y ajustes que desees aplicar.

- Ejecutar todo el sistema de forma dockerizada, ya sea:

    - Todo en un √∫nico contenedor y una instancia, si prefieres una ejecuci√≥n integrada.
    - Por contenedor separando cada app en una instancia.

Esto te permite flexibilidad para realizar pruebas seg√∫n el entorno o flujo que necesites validar.

‚ö†Ô∏è Independientemente de la opci√≥n que elijas, es importante que utilices un entorno virtual para ejecutar los comandos.

‚ö†Ô∏è Adem√°s, si decides probar dos opciones al mismo tiempo, no deben ejecutarse simult√°neamente,
ya que los puertos son los mismos y se generar√° un conflicto.

## üê≥ Opci√≥n 1: Dockerizaci√≥n (recomendada para pruebas y producci√≥n)

Para ejecutar las aplicaciones dentro de contenedores Docker, hay dos maneras de hacerlo:

### 1) Dockerfile para Streamlit + FastAPI (Parecido a ejecutar todo en una sola m√°quina)

Esto ejecuta el archivo `Dockerfile` con la configuraci√≥n de `supervisord.conf`
para iniciar tanto FastAPI como Streamlit **_en un solo contenedor y una sola m√°quina_**.

```bash
docker build -t rba-anomaly-dashboard .
```

Luego ejecuta

```bash
docker run -p 8501:8501 -p 4200:4200 rba-anomaly-dashboard
```

### 2) Docker compose para Streamlit + FastAPI (Parecido a ejecutar cada app en instancias)

Esto ejecuta el archivo `docker-compose.yml` para iniciar un contenedor con FastAPI y Streamlit
**_en un solo contenedor y dos instancias_**.

```bash
docker-compose build
```

Luego ejecuta

```bash
docker-compose up -d
```

Nota: El API cambia ligeramente con esta opci√≥n en tu m√°quina local, el url es http://fastapi:4200/

## Opci√≥n 2: Ejecutar de manera individual (recomendada para pruebas y desarrollo)

### 1) üåê Ejecutar la API (individual)

Con el entorno virtual activo, puedes lanzar el servidor de la API.
Esta es la parte central del proyecto, que manejar√° la l√≥gica de la aplicaci√≥n.

```bash
uvicorn app.api:app --reload --port 4200
```

### 2) üñ•Ô∏è Ejecutar la aplicaci√≥n cliente (individual)

Abre una nueva ventana de tu terminal, aseg√∫rate de que el entorno virtual est√© activo y ejecuta el cliente de
Streamlit.
Aqu√≠ es donde ver√°s la interfaz de usuario.

```bash
streamlit run app/client.py
```

Nota: Es crucial que utilices el entorno virtual para este comando.

### 3) (Opcional) üß† Ejecutar langgraph para analizarlo el flujo de agentes (individual)

Si quieres explorar el flujo de agentes de la IA, ejecuta este comando. Te permitir√° visualizar c√≥mo est√° construido el
grafo, qu√© datos se necesitan y c√≥mo se comunican los agentes entre s√≠.

```bash
langgraph dev
```

---
# Pruebas: Demostraci√≥n del funcionamiento de las apps

Una vez tengas corriendo las aplicaciones por cualquiera de las tres opciones anteriores, llega el momento de probar, para ello
ejecuta las siguientes peticiones en postman o por la consola.

Recuerda que si usaste docker en la segunda opci√≥n cambia el dominio
por `http://fastapi:4200` por ejemplo: `http://fastapi:4200/health`

```bash
curl --location 'http://localhost:4200/health'
```

```bash
curl --location 'http://localhost:4200/analyze' \
--header 'Content-Type: application/json' \
--data '[
  {
    "ip_address": "1.1.1.1",
    "country": "CO",
    "asn": 15169,
    "user_agent_string": "Mozilla/5.0",
    "browser_name_and_version": "Chrome 125.0",
    "os_name_and_version": "Windows 11",
    "device_type": "desktop",
    "login_successful": 1
  },
  {
    "ip_address": "8.8.8.8",
    "country": "US",
    "asn": 13335,
    "user_agent_string": "Mozilla/5.0",
    "browser_name_and_version": "Chrome 125.0",
    "os_name_and_version": "macOS 14",
    "device_type": "desktop",
    "login_successful": 0
  }
]
'
```
Por otro lado, puedes acceder desde tu navegador al siguiente dominio http://localhost:8501/
para probar el dashboard.


### Prueba validaci√≥n del API
![img1](assets/img1.png)

### Ejecuci√≥n de detecci√≥n de anomal√≠as via API
![img1](assets/img2.png)

### Vista inicial del dashboard interactivo
![img1](assets/img3.png)

### Ingresando datos desde el clipboard
![img1](assets/img4.png)

### Respuesta generada por el LLM
![img1](assets/img5.png)

### Resultados obtenidos de la predicci√≥n del Modelo de ML 
![img1](assets/img6.png)

### Datos cargados en memoria, preparados para analizarse
![img1](assets/img7.png)